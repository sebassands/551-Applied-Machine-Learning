{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MP2_Lia.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R-7Hefg9tm4",
        "colab_type": "text"
      },
      "source": [
        "# Loading data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MfErzzsVGL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "from sklearn.datasets import load_files\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer \n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "import time\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_validate\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv3Nwx_hSqrw",
        "colab_type": "code",
        "outputId": "f8aca3a5-e777-4590-bac3-76dc4ee53000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# Get the Imdb data (will go in Colab's \"content\" folder)\n",
        "# Must run this once per 12 hours (files deleted from Colab's memory)\n",
        "! git clone https://gitlab.com/formenli/aclimdbdata.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'aclimdbdata'...\n",
            "remote: Enumerating objects: 98534, done.\u001b[K\n",
            "remote: Counting objects: 100% (98534/98534), done.\u001b[K\n",
            "remote: Compressing objects: 100% (98513/98513), done.\u001b[K\n",
            "remote: Total 98534 (delta 25), reused 98514 (delta 13), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (98534/98534), 94.86 MiB | 10.05 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n",
            "Checking out files: 100% (50030/50030), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ap-zU7VtQVWR",
        "colab": {}
      },
      "source": [
        "# Load Imdb data. Takes in path to directory containing sub dirs that contain data of each output class respectively.\n",
        "# Outputs a dict-like object, where .data is the data, .targets are the output classes, and .target_names is a list\n",
        "# of the names given to each target (where the number corresponds to the index)\n",
        "imdbTrain = load_files(\"aclimdbdata/train/\")\n",
        "imdbTest = load_files(\"aclimdbdata/test/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYEi5dfaQV-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load subsets for debugging\n",
        "imdbSubsetTrain = load_files(\"aclimdbdata/subsetTrain/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AGss-q497KI",
        "colab_type": "text"
      },
      "source": [
        "# Multinomial NB on Imdb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys4XyFPXfDeR",
        "colab_type": "code",
        "outputId": "7c0ec6b7-ce8c-4de5-b78a-aae8acb7b780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Preliminary playing with the Imdb data, Multinomial Naive Bayes fit\n",
        "# NB often used as a baseline because no hyperparams to tune.\n",
        "\n",
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', MultinomialNB()),\n",
        "    ])\n",
        "text_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "\n",
        "# Predict \n",
        "predicted = text_clf.predict(imdbTest.data)\n",
        "accuracy_score(imdbTest.target, predicted)    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.82956"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z09ofwuKh3ym",
        "colab_type": "text"
      },
      "source": [
        "# Logistic regression on Imdb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xYWjSh9SyEl",
        "colab_type": "code",
        "outputId": "e346437f-b1ec-445a-badb-f8bd72370707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# SKLearn default logistic regression\n",
        "# Penalty: l2\n",
        "# Solver lbfgs\n",
        "# Inverse reg strength (C): 1.0\n",
        "\n",
        "default_LR_clf = Pipeline([\n",
        "                           ('vect', CountVectorizer()),\n",
        "                           ('tfidf', TfidfTransformer()),\n",
        "                           ('clf', LogisticRegression()),\n",
        "])\n",
        "\n",
        "LR_imdb_default_results = cross_validate(default_LR_clf, imdbTrain.data, imdbTrain.target, return_train_score=True, cv=5, n_jobs=-1, verbose=1)\n",
        "print('CV accuracy: ', np.mean(LR_imdb_default_results['test_score']))\n",
        "print('Mean fit time: ', np.mean(LR_imdb_default_results['fit_time']))\n",
        "print('Train acc: ', np.mean(LR_imdb_default_results['train_score']))\n",
        "\n",
        "start = time.time()\n",
        "default_LR_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "print('Train time:', time.time() - start)\n",
        "# Training accuracy\n",
        "trainPredictions = default_LR_clf.predict(imdbTrain.data)\n",
        "print('Train accuracy: ', accuracy_score(imdbTrain.target, trainPredictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CV accuracy:  0.7248545294639129\n",
            "Mean fit time:  42.02966232299805\n",
            "Train acc:  0.910243944402449\n",
            "Train time: 5.501657485961914\n",
            "Train accuracy:  0.93328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH7YoXyhlAK-",
        "colab_type": "code",
        "outputId": "6d41fb37-0fbd-4c6a-f20d-d234bd37b76b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# Grid search of non continuous parameters\n",
        "# Only sensible combinations\n",
        "# Group 1: penalty=l2,none; solvers=lbfgs, newton-cg, sag, saga\n",
        "\n",
        "# Build pipeline\n",
        "LR1_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LogisticRegression()),\n",
        "])\n",
        "# Params for grid search\n",
        "params = {'clf__penalty': ('l2','none'),\n",
        "          'clf__C': (0.001, 0.1, 1, 10),\n",
        "          'clf__solver': ('lbfgs', 'newton-cg', 'sag', 'saga')}\n",
        "\n",
        "LR1_gs_clf = GridSearchCV(LR1_clf, params, n_jobs=-1, return_train_score=True)\n",
        "LR1_gs_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "\n",
        "for param_name in sorted(params.keys()):\n",
        "  print(\"%s : %r\" % (param_name, LR1_gs_clf.best_params_[param_name]))\n",
        "print('Train time for best params:', LR1_gs_clf.cv_results_['mean_fit_time'][LR1_gs_clf.best_index_])\n",
        "print('Train acc for best params:', LR1_gs_clf.cv_results_['mean_train_score'][LR1_gs_clf.best_index_])\n",
        "print('CV acc for best params:', LR1_gs_clf.best_score_)\n",
        "\n",
        "# Check how the best performs:\n",
        "LR1_best_clf = Pipeline([\n",
        "                         ('vect', CountVectorizer()),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('clf', LogisticRegression(penalty=LR1_gs_clf.best_params_['clf__penalty'],\n",
        "                                           solver=LR1_gs_clf.best_params_['clf__solver'],\n",
        "                                           C=LR1_gs_clf.best_params_['clf__C']))\n",
        "])\n",
        "\n",
        "start = time.time()\n",
        "LR1_best_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = LR1_best_clf.predict(imdbTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, imdbTrain.target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clf__C : 10\n",
            "clf__penalty : 'l2'\n",
            "clf__solver : 'newton-cg'\n",
            "Train time for best params: 8.83703408241272\n",
            "Train acc for best params: 0.9895900000000001\n",
            "CV acc for best params: 0.8945599999999999\n",
            "Train time: 8.308072328567505\n",
            "Train acc: 0.98764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fegoxv8EuVI5",
        "colab_type": "code",
        "outputId": "966dead1-4e5f-4894-bf55-234c4d948c60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "# Exploring group 1 results a little more fully\n",
        "for p, t, r in zip(LR1_gs_clf.cv_results_['params'], LR1_gs_clf.cv_results_['mean_fit_time'], LR1_gs_clf.cv_results_['mean_test_score']):\n",
        "  print(p,t,r)\n",
        "# Output shows that essentially lbfgs and newton-cg come out with the same acc but lbfgs is consistently faster => preferred."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'clf__C': 0.001, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'} 5.338502073287964 0.76908\n",
            "{'clf__C': 0.001, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'} 5.825904798507691 0.76908\n",
            "{'clf__C': 0.001, 'clf__penalty': 'l2', 'clf__solver': 'sag'} 7.357763147354126 0.76956\n",
            "{'clf__C': 0.001, 'clf__penalty': 'l2', 'clf__solver': 'saga'} 7.315402221679688 0.7696799999999999\n",
            "{'clf__C': 0.001, 'clf__penalty': 'none', 'clf__solver': 'lbfgs'} 7.226515674591065 0.8788\n",
            "{'clf__C': 0.001, 'clf__penalty': 'none', 'clf__solver': 'newton-cg'} 10.254513788223267 0.87748\n",
            "{'clf__C': 0.001, 'clf__penalty': 'none', 'clf__solver': 'sag'} 10.751192045211791 0.88484\n",
            "{'clf__C': 0.001, 'clf__penalty': 'none', 'clf__solver': 'saga'} 11.900542497634888 0.88644\n",
            "{'clf__C': 0.1, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'} 5.85276689529419 0.84856\n",
            "{'clf__C': 0.1, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'} 6.863955497741699 0.84856\n",
            "{'clf__C': 0.1, 'clf__penalty': 'l2', 'clf__solver': 'sag'} 5.843652582168579 0.84856\n",
            "{'clf__C': 0.1, 'clf__penalty': 'l2', 'clf__solver': 'saga'} 6.473183059692383 0.84856\n",
            "{'clf__C': 0.1, 'clf__penalty': 'none', 'clf__solver': 'lbfgs'} 6.89566707611084 0.8788\n",
            "{'clf__C': 0.1, 'clf__penalty': 'none', 'clf__solver': 'newton-cg'} 10.648595285415649 0.87748\n",
            "{'clf__C': 0.1, 'clf__penalty': 'none', 'clf__solver': 'sag'} 10.81052269935608 0.88504\n",
            "{'clf__C': 0.1, 'clf__penalty': 'none', 'clf__solver': 'saga'} 12.021816444396972 0.8865999999999999\n",
            "{'clf__C': 1, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'} 7.535350894927978 0.8883599999999999\n",
            "{'clf__C': 1, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'} 8.114321851730347 0.88832\n",
            "{'clf__C': 1, 'clf__penalty': 'l2', 'clf__solver': 'sag'} 6.156930828094483 0.88832\n",
            "{'clf__C': 1, 'clf__penalty': 'l2', 'clf__solver': 'saga'} 6.507105445861816 0.88832\n",
            "{'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'lbfgs'} 7.214608478546142 0.8788\n",
            "{'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'newton-cg'} 11.480475378036498 0.87748\n",
            "{'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'sag'} 11.068675231933593 0.8855999999999999\n",
            "{'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'saga'} 12.328274488449097 0.88612\n",
            "{'clf__C': 10, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'} 8.041561269760132 0.8944799999999999\n",
            "{'clf__C': 10, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'} 8.83703408241272 0.8945599999999999\n",
            "{'clf__C': 10, 'clf__penalty': 'l2', 'clf__solver': 'sag'} 6.88305287361145 0.8945599999999999\n",
            "{'clf__C': 10, 'clf__penalty': 'l2', 'clf__solver': 'saga'} 8.862261962890624 0.89452\n",
            "{'clf__C': 10, 'clf__penalty': 'none', 'clf__solver': 'lbfgs'} 7.233242607116699 0.8788\n",
            "{'clf__C': 10, 'clf__penalty': 'none', 'clf__solver': 'newton-cg'} 11.721188020706176 0.87748\n",
            "{'clf__C': 10, 'clf__penalty': 'none', 'clf__solver': 'sag'} 11.286521673202515 0.88444\n",
            "{'clf__C': 10, 'clf__penalty': 'none', 'clf__solver': 'saga'} 11.740050411224365 0.8868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf4RrmKh84zS",
        "colab_type": "code",
        "outputId": "f7cbaf4e-6784-4df8-d8b8-b754b265bbc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Grid search of non continuous parameters\n",
        "# Only sensible combinations\n",
        "# Group 2: solver=liblinear, penalty = l2,l1, dual = False\n",
        "\n",
        "# Build pipeline\n",
        "LR2_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LogisticRegression(solver='liblinear', dual=False)),\n",
        "])\n",
        "# Params for grid search\n",
        "params = {'clf__penalty': ('l2','l1'),\n",
        "          'clf__C': (0.001, 0.1, 1, 5, 10, 15)}\n",
        "\n",
        "# njobs=1 here to stop parallel processing - causes memory leaks for this solver\n",
        "# https://github.com/ageron/handson-ml/issues/315 \n",
        "LR2_gs_clf = GridSearchCV(LR2_clf, params, n_jobs=1, return_train_score=True)\n",
        "LR2_gs_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "\n",
        "for param_name in sorted(params.keys()):\n",
        "  print(\"%s : %r\" % (param_name, LR2_gs_clf.best_params_[param_name]))\n",
        "print('Train time for best params:', LR2_gs_clf.cv_results_['mean_fit_time'][LR2_gs_clf.best_index_])\n",
        "print('Train acc for best params:', LR2_gs_clf.cv_results_['mean_train_score'][LR2_gs_clf.best_index_])\n",
        "print('CV acc for best params:', LR2_gs_clf.best_score_)\n",
        "\n",
        "# Check how the best performs:\n",
        "LR2_best_clf = Pipeline([\n",
        "                         ('vect', CountVectorizer()),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('clf', LogisticRegression(penalty=LR2_gs_clf.best_params_['clf__penalty'],\n",
        "                                           solver='liblinear',\n",
        "                                           dual=False,\n",
        "                                           C=LR2_gs_clf.best_params_['clf__C']))\n",
        "])\n",
        "\n",
        "start = time.time()\n",
        "LR2_best_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = LR2_best_clf.predict(imdbTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, imdbTrain.target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clf__C : 10\n",
            "clf__penalty : 'l2'\n",
            "Train time for best params: 5.303345966339111\n",
            "Train acc for best params: 0.9895900000000001\n",
            "CV acc for best params: 0.8945599999999999\n",
            "Train time: 6.503049373626709\n",
            "Train acc: 0.98764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4a157373-1ed9-4dba-91e0-8b19cccd6dfb",
        "id": "FdCYtVAoGVmZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Grid search of non continuous parameters\n",
        "# Only sensible combinations\n",
        "# Group 3: solver=liblinear, penalty = l2, dual = True \n",
        "\n",
        "# Build pipeline\n",
        "LR3_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LogisticRegression(solver='liblinear', dual=True, penalty='l2')),\n",
        "])\n",
        "# Params for grid search\n",
        "params = {'clf__C': (0.001, 0.1, 1, 5, 10, 15)}\n",
        "\n",
        "LR3_gs_clf = GridSearchCV(LR3_clf, params, n_jobs=-1, return_train_score=True)\n",
        "LR3_gs_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "\n",
        "for param_name in sorted(params.keys()):\n",
        "  print(\"%s : %r\" % (param_name, LR3_gs_clf.best_params_[param_name]))\n",
        "print('Train time for best params:', LR3_gs_clf.cv_results_['mean_fit_time'][LR3_gs_clf.best_index_])\n",
        "print('Train acc for best params:', LR3_gs_clf.cv_results_['mean_train_score'][LR3_gs_clf.best_index_])\n",
        "print('CV acc for best params:', LR3_gs_clf.best_score_)\n",
        "\n",
        "# Check how the best performs:\n",
        "LR3_best_clf = Pipeline([\n",
        "                         ('vect', CountVectorizer()),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('clf', LogisticRegression(penalty='l2',\n",
        "                                           solver='liblinear',\n",
        "                                           dual=True,\n",
        "                                           C=LR3_gs_clf.best_params_['clf__C']))\n",
        "])\n",
        "\n",
        "start = time.time()\n",
        "LR3_best_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = LR3_best_clf.predict(imdbTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, imdbTrain.target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clf__C : 10\n",
            "Train time for best params: 6.603286170959473\n",
            "Train acc for best params: 0.9895900000000001\n",
            "CV acc for best params: 0.8945599999999999\n",
            "Train time: 4.774367570877075\n",
            "Train acc: 0.98764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIA9OoSJIj_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grid search of non continuous parameters\n",
        "# Only sensible combinations\n",
        "# Group 4: solver=saga, penalty = l1\n",
        "# Took forever, ditched it\n",
        "\n",
        "# Build pipeline\n",
        "LR4_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LogisticRegression(solver='saga', penalty='l1', max_iter=1500)),\n",
        "])\n",
        "# From first run, saga needs more iterations\n",
        "# Params for grid search\n",
        "params = {'clf__C': (0.001, 0.1, 1, 5, 10, 15)}\n",
        "\n",
        "LR4_gs_clf = GridSearchCV(LR4_clf, params, n_jobs=-1, return_train_score=True)\n",
        "LR4_gs_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "\n",
        "for param_name in sorted(params.keys()):\n",
        "  print(\"%s : %r\" % (param_name, LR4_gs_clf.best_params_[param_name]))\n",
        "print('Train time for best params:', LR4_gs_clf.cv_results_['mean_fit_time'][LR4_gs_clf.best_index_])\n",
        "print('Train acc for best params:', LR4_gs_clf.cv_results_['mean_train_score'][LR4_gs_clf.best_index_])\n",
        "print('CV acc for best params:', LR4_gs_clf.best_score_)\n",
        "\n",
        "# Check how the best performs:\n",
        "LR4_best_clf = Pipeline([\n",
        "                         ('vect', CountVectorizer()),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('clf', LogisticRegression(penalty='l1',\n",
        "                                           solver='saga',\n",
        "                                           C=LR4_gs_clf.best_params_['clf__C']))\n",
        "])\n",
        "\n",
        "start = time.time()\n",
        "LR4_best_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = LR4_best_clf.predict(imdbTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, imdbTrain.target))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0H_QVo5HnrW",
        "colab_type": "code",
        "outputId": "053af0e0-2399-4e48-f989-8c703db46d7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Finer grid search\n",
        "# Decided group three was best because faster but same results as group 1\n",
        "# liblinear, C ~= 10, penalty = l2\n",
        "\n",
        "# Build pipeline\n",
        "LR3_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LogisticRegression(solver='liblinear', dual=True, penalty='l2')),\n",
        "])\n",
        "# Params for grid search\n",
        "params = {'clf__C': (1.0, 2.5, 5.0,6.0,7.0,8.0,9.0,9.5,10,10.5,11)}\n",
        "\n",
        "LR3_gs_clf = GridSearchCV(LR3_clf, params, n_jobs=-1, return_train_score=True)\n",
        "LR3_gs_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "\n",
        "for param_name in sorted(params.keys()):\n",
        "  print(\"%s : %r\" % (param_name, LR3_gs_clf.best_params_[param_name]))\n",
        "print('Train time for best params:', LR3_gs_clf.cv_results_['mean_fit_time'][LR3_gs_clf.best_index_])\n",
        "print('Train acc for best params:', LR3_gs_clf.cv_results_['mean_train_score'][LR3_gs_clf.best_index_])\n",
        "print('CV acc for best params:', LR3_gs_clf.best_score_)\n",
        "\n",
        "# Check how the best performs:\n",
        "LR3_best_clf = Pipeline([\n",
        "                         ('vect', CountVectorizer()),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('clf', LogisticRegression(penalty='l2',\n",
        "                                           solver='liblinear',\n",
        "                                           dual=True,\n",
        "                                           C=LR3_gs_clf.best_params_['clf__C']))\n",
        "])\n",
        "\n",
        "start = time.time()\n",
        "LR3_best_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = LR3_best_clf.predict(imdbTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, imdbTrain.target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clf__C : 8.0\n",
            "Train time for best params: 6.687569856643677\n",
            "Train acc for best params: 0.9857700000000001\n",
            "CV acc for best params: 0.89496\n",
            "Train time: 4.922297477722168\n",
            "Train acc: 0.98364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zu8DDWMgYYj",
        "colab_type": "code",
        "outputId": "77443e38-5104-4593-fd12-5448bce98e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# on the test set\n",
        "LR_imdb_best = Pipeline([\n",
        "                         ('vect', CountVectorizer()),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('clf', LogisticRegression(penalty='l2',\n",
        "                                           solver='liblinear',\n",
        "                                           dual=True,\n",
        "                                           C=8.0))\n",
        "])\n",
        "LR_imdb_best.fit(imdbTrain.data, imdbTrain.target)\n",
        "LRimdbBestPreds = LR_imdb_best.predict(imdbTest.data)\n",
        "print(\"LR Imdb accuracy: \", accuracy_score(imdbTest.target, LRimdbBestPreds))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR Imdb accuracy:  0.88224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80-CRlR8uQJB",
        "colab_type": "code",
        "outputId": "ab003ac1-e41d-4a6a-ffc9-2acdea4b8894",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "# Looking at CV results mean acc for all C\n",
        "# Made a plot to show why its not worth tuning C anymore.\n",
        "%matplotlib inline \n",
        "cs = []\n",
        "cvAccs = []\n",
        "LR_imdb_cplot_clf = Pipeline([\n",
        "                              ('vect', CountVectorizer()),\n",
        "                              ('tfidf', TfidfTransformer()),\n",
        "                              ('clf', LogisticRegression(penalty='l2', solver='liblinear', dual=True))\n",
        "])\n",
        "params = {'clf__C': (1.0, 2.5, 5.0,6.0,7.0,8.0,9.0,9.5,10,10.5,11)}\n",
        "LR_imdb_cplot_gs = GridSearchCV(LR_imdb_cplot_clf, params, n_jobs=1) \n",
        "LR_imdb_cplot_gs.fit(imdbTrain.data, imdbTrain.target)\n",
        "for p, r in zip(LR_imdb_cplot_gs.cv_results_['params'], LR_imdb_cplot_gs.cv_results_['mean_test_score']):\n",
        "    print(p,r)\n",
        "    cs.append(p['clf__C'])\n",
        "    cvAccs.append(r)\n",
        "fig = plt.figure()\n",
        "plt.plot(cs, cvAccs, 'b.')\n",
        "plt.xlabel('Inverse Regularization Parameter')\n",
        "plt.ylabel('Cross validated accuracy')\n",
        "plt.savefig('imdbCTunePlot', dpi=400)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'clf__C': 1.0} 0.88832\n",
            "{'clf__C': 2.5} 0.8938\n",
            "{'clf__C': 5.0} 0.8943199999999999\n",
            "{'clf__C': 6.0} 0.8946\n",
            "{'clf__C': 7.0} 0.8948\n",
            "{'clf__C': 8.0} 0.89496\n",
            "{'clf__C': 9.0} 0.8947999999999998\n",
            "{'clf__C': 9.5} 0.8946799999999999\n",
            "{'clf__C': 10} 0.8945599999999999\n",
            "{'clf__C': 10.5} 0.89444\n",
            "{'clf__C': 11} 0.8943199999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dfZxdVX3v8c+XQIhEiUiCVUKatKKS\ngkIZkfjQRjEKUcFq9RqFCxah7RXEFG/Fir0p2qq94kstDzVoCEULArY2RSQoJNhCFCZgEoKAKVUI\nUBMrzz7EhG//2GvgMJlM9klmzzkz832/Xud19l5n731++2Ryfmettfdask1ERERdu3Q6gIiIGFmS\nOCIioi1JHBER0ZYkjoiIaEsSR0REtGXXTgcwHCZPnuzp06d3OoyIiBFl5cqVP7U9pX/5mEgc06dP\np7e3t9NhRESMKJJ+PFB5mqoiIqItSRwREdGWJI6IiGhLEkdERLSl0cQh6UhJd0paJ+mMAV6fJmmZ\npFslrZY0t5SPl3ShpDWSVkma3bLP8nLM75fHPk2eQ0REPF1jV1VJGgecC8wB1gM3S1pi+/aWzc4E\nLrN9vqSZwFXAdOAkANsHlcTwTUkvs/1E2e/dtnOZVEREBzRZ4zgMWGf7btubgEuBY/ptY2DPsjwJ\nuL8szwSuA7C9AXgI6Gkw1ogYBitWwCc+UT3HyNXkfRz7Ave2rK8HXt5vmwXANZJOBSYCryvlq4Cj\nJV0C7AccWp5vKq9fKGkL8DXg4x5gbHhJJwMnA0ybNm0ozicidsKKFXDEEbBpE4wfD9deC7NmdTqq\n2BGd7hyfByy2PRWYC1wsaRdgEVWi6QU+C9wIbCn7vNv2QcCry+O4gQ5se6HtHts9U6ZsdeNjRAyz\n5curpLFlS/W8fHmnI4od1WTiuI+qltBnailrdSJwGYDtFcAEYLLtzbbn2z7Y9jHAs4G7ynb3ledH\ngX+kahKLiC43e3ZV0xg3rnqePbvTEcWOajJx3AzsL2mGpPHAO4El/ba5BzgCQNIBVIljo6Q9JE0s\n5XOAzbZvl7SrpMmlfDfgTcBtDZ5DRAyRWbOq5qmPfSzNVCNdY30ctjdLOgVYCowDFtleK+ksoNf2\nEuB04AJJ86k6yk+w7XIl1VJJT1DVUvqao3Yv5buVY34buKCpc4gYrVasqJqKZs8e3i/wWbM6kzA6\ndb6jlcbCnOM9PT3OIIcRlbHWST3WzncoSVppe6srWjvdOR4Rw2ysdVKPtfMdDkkcEWPMWOukHmvn\nOxzGxHwcEfGUvk7qsdLmPxTnmz6Sp0sfR0TEIMZyH0n6OCK6TIbfGBnSR7K1NFVFdMBY/hU70vT1\nkfT9W7XbRzIam7mSOCI6YKBfsaPlS2W02Zk+ktH6AyGJI6IDdvZXbAyvHb1xcbT+QEjiiOiAsXZl\n01g1Wn8gJHFEdEinht+I4bOzPxC6tX8kiSMiokE7+gOhm/tHcjluREQX6ubLgJM4YszL/RTRjXZ2\nqJQm/67TVBVjWjc3B8TY1s2XASdxxJg2Wi+XjNGhWy8DTlNVjGkZOTVGo6b/rlPjiDEt91PEaNT0\n33VGx42IiAFldNyIiBgSSRwREdGWJI6IiGhLo4lD0pGS7pS0TtIZA7w+TdIySbdKWi1pbikfL+lC\nSWskrZI0e4B9l0i6rcn4IyJia40lDknjgHOBo4CZwDxJM/ttdiZwme1DgHcC55XykwBsHwTMAc6W\n9GSskt4KPNZU7BERsW1N1jgOA9bZvtv2JuBS4Jh+2xjYsyxPAu4vyzOB6wBsbwAeAnoAJD0T+DPg\n4w3GHhER29Bk4tgXuLdlfX0pa7UAOFbSeuAq4NRSvgo4WtKukmYAhwL7ldc+BpwN/HywN5d0sqRe\nSb0bN27cqROJiIindLpzfB6w2PZUYC5wcWmSWkSVaHqBzwI3AlskHQz8tu1/3t6BbS+03WO7Z8qU\nKc2dQUTEGNPkneP38VQtAWBqKWt1InAkgO0VkiYAk0vz1Py+jSTdCNwF/D7QI+lHVLHvI2m57dlN\nnURERDxdkzWOm4H9Jc2QNJ6q83tJv23uAY4AkHQAMAHYKGkPSRNL+Rxgs+3bbZ9v+/m2pwOvAu5K\n0oiIGF6N1Thsb5Z0CrAUGAcssr1W0llAr+0lwOnABZLmU3WUn2DbkvYBlkp6gqqWclxTcY5G3Trd\nZESMDhmrapTJ/BIRMVQyVtUY0c3TTUbE6JDEMcpkfomIaFrm4xhlMr9ERDRtu4lD0t62/3s4gomh\nsaPTTUZE1FGnqeq7ki6XNFeSGo8oIiK6Wp3E8UJgIdUlsT+U9DeSXthsWBER0a22mzhc+ZbteVSj\n1h4P3CTpeklpEImIGGNq9XEAx1LVOH5CNRDhEuBg4HJgRpMBRkREd6lzVdUK4GLgLbbXt5T3Svr7\nZsKKiIhuVSdxvMjbuL3c9qeGOJ6IiOhydTrHr5H07L4VSXtJWtpgTBER0cXqJI4pth/qW7H9ILBP\ncyFFREQ3q5M4tkia1rci6TepRrKNiIgxqE4fx0eAf5d0PSDg1cDJjUYVERFda7uJw/bVkn4XOLwU\nfcD2T5sNKyIiulXdQQ63ABuoZuibKQnb32kurIiI6FZ1bgB8L3Aa1Zzh36eqeawAXttsaBER0Y3q\ndI6fBrwM+LHt1wCHAA8NvktERIxWdRLHL23/EkDS7rbvAF7UbFgREdGt6vRxrC83AH4d+JakB4Ef\nNxtWRER0qzqj4/6B7YdsLwA+CnwJeEudg0s6UtKdktZJOmOA16dJWibpVkmrJc0t5eMlXShpjaRV\nkma37HN1KVsr6e8ljat5rhERMQQGTRySxkm6o2/d9vW2l9jetL0Dly/0c4GjgJnAPEkz+212JnCZ\n7UOAdwLnlfKTyvsdBMwBzpbUF+s7bL8UOBCYArx9e7FERMTQGTRx2N4C3Nl653gbDgPW2b67JJpL\ngWP6vwWwZ1meBNxflmcC15UYNlB1xveU9UfKNrsC48ld7BERw6pO5/hewFpJ10pa0veosd++wL0t\n6+tLWasFwLGS1gNXUc31AbAKOFrSrpJmAIcC+/XtVAZZ3AA8ClxRI5aIiBgidTrHP9rg+88DFts+\nu8wmeLGkA4FFwAFAL1VH/I1UNyECYPsNkiYAX6G6n+Rb/Q8s6WTK0CjTpu1IhSkiIgZSZ8iR63fw\n2PfRUkuguoHwvn7bnAgcWd5nRUkGk0vz1Py+jSTdCNzVL65fSvoXquavrRKH7YVUc6XT09OT5qyI\niCGy3aYqSY9KeqQ8filpi6RHtrcfcDOwv6QZksZTdX73b+K6BziivM8BVEOabJS0h6SJpXwOsNn2\n7ZKeKel5pXxX4I3AHURExLCpU+N4Vt+yJFH9wj9823s8ud9mSacAS4FxwCLbayWdBfTaXgKcDlwg\naT5VJ/cJti1pH2CppCeoainHlcNOBJZI2p0q6S0DMn1tRMQw0jZmhR18J+nWcgntiNDT0+Pe3t5O\nhxERMaJIWmm7p395nUEO39qyugvVZbG/HMLYIiJiBKlzVdWbW5Y3Az9i6/sxIiJijKjTx/Ge4Qgk\nIiJGhjpXVV1UBjnsW99L0qJmw4qIiG5V587xl9h+cv4N2w9SzckRERFjUJ3EsYukvfpWJD2H+lPO\nRkTEKFMnAZwNrJB0eVl/O/DXzYUUERHdrE7n+D9I6uWpOcbfavv2ZsOKiIhuVec+jsOBtbbPKet7\nSnq57e81Hl1ERHSdOn0c5wOPtaw/VsoiImIMqpM45JZxSWw/QTrHIyLGrDqJ425J75e0W3mcBtzd\ndGAREdGd6iSOPwFeQTVK7Xrg5ZQJkiIiYuypc1XVBqq5NCIiImpdVTWBaqa+36GaaAkA23/UYFwR\nEdGl6jRVXQz8BvAG4HqqKWAfbTKoiIjoXnUSxwtsfxR43PZFVNO1vrzZsCIiolvVSRy/Ls8PSToQ\nmATs01xIERHRzercj7GwDHJ4JrAEeCbw0UajioiIrlXnqqovlsXvAL/VbDgREdHt6jRVRUREPKnR\nxCHpSEl3Slon6YwBXp8maZmkWyWtljS3lI+XdKGkNZJWSZpdyveQ9A1Jd0haK+mTTcYfERFbayxx\nSBoHnAscBcwE5kma2W+zM4HLbB9CdZPheaX8JADbBwFzgLMl9cX6adsvppqF8JWSjmrqHCIiYmvb\n7OOQ9NbBdrT9T9s59mHAOtt3l+NdChwDtM7lYWDPsjwJuL8szwSuK++zQdJDQI/tm4BlpXyTpFuo\n7iuJiIhhMljn+JvL8z5UY1VdV9ZfA9wIbC9x7Avc27LeN85VqwXANZJOBSYCryvlq4CjJV0C7Acc\nWp5v6ttR0rNLjJ8b6M0lnUwZU2vatGnbCTUiIuraZlOV7ffYfg+wGzDT9ttsv41q6JHdhuj95wGL\nbU8F5gIXlyapRVSJphf4LFWi2tK3k6RdgUuAz/fVaAaIf6HtHts9U6ZMGaJwIyKizn0c+9l+oGX9\nJ0Cdn/D3UdUS+kwtZa1OBI4EsL2ijIs1uQysOL9vI0k3Ane17LcQ+KHtz9aIIyIihlCdzvFrJS2V\ndIKkE4BvAN+usd/NwP6SZkgaT9X5vaTfNvcARwBIOoBqEMWN5eqpiaV8DrC5b55zSR+n6g/5QI0Y\nIiJiiNW5AfAUSX8A/F4pWmj7n2vst1nSKcBSYBywyPZaSWcBvbaXAKcDF0iaT9VRfoJtS9oHWCrp\nCapaynEAkqYCHwHuAG6RBHBOy02KERHRMLXMCrvtjaTfBPa3/W1JewDjbI+YEXJ7enrc29vb6TAi\nIkYUSStt9/Qv325TlaSTgCuAL5SifYGvD214ERExUtTp43gf8ErgEQDbPySj40ZEjFl1EsevbG/q\nWymXwm6/fSsiIkalOonjekl/ATyjXOF0OfCvzYYVERHdqk7iOAPYCKwB/hi4yvZHGo0qIiK6Vp0b\nAE+1/Tnggr4CSaeVsoiIGGPq1DiOH6DshCGOIyIiRojBRsedB7wLmCGp9Y7vZwE/azqwiIjoToM1\nVd0IPABMBs5uKX8UWN1kUBER0b22mThs/xj4MTBr+MKJiIhuV+fO8cMl3SzpMUmbJG2R9MhwBBcR\nEd2nTuf4OVTzZvwQeAbwXqopYSMiYgyqNee47XVUAxtusX0hZQ6NiIgYe+rcx/HzMp/G9yX9LVWH\nea2EExERo0+dBHAc1XwapwCPU83q97Ymg4qIiO5VZyKnH5fFXwB/1Ww4ERHR7Qa7AXANg4yCa/sl\njUQUERFdbbAax5vK8/vK88Xl+VgyrHpExJi1vRsAkTTH9iEtL31I0i1Uo+ZGRMQYU6dzXJJe2bLy\nipr7RUTEKFTnctwTgUWSJgECHgT+qNGoIiKia2235mB7pe2XAi8FXmL7YNu31Dm4pCMl3SlpnaSt\nmrYkTZO0TNKtklZLmlvKx0u6UNIaSaskzW7Z568l3SvpsdpnGRERQ2awq6qOtf1lSX/WrxwA258Z\n7MCSxlENTTIHWA/cLGmJ7dtbNjsTuMz2+ZJmAlcB04GTynscJGkf4JuSXmb7Cappa8+hGgIlIiKG\n2WA1jonl+VnbeGzPYcA623fb3gRcChzTbxsDe5blScD9ZXkmcB2A7Q3AQ0BPWf+u7QdqvH9ERDRg\nsKuqvlCed/Smv32Be1vW1wMv77fNAuAaSadSJarXlfJVwNGSLqG6U/3Q8nxT3TeXdDJwMsC0adN2\nIPyIiBjIYE1Vnx9sR9vvH4L3nwcstn22pFnAxZIOBBYBBwC9VHOC3AhsaefAthcCCwF6enpy30lE\nxBAZ7KqqlTt57Puoagl9ppayVidSRtq1vULSBGByaZ6a37eRpBuBu3YynoiIGAKDNVVdtJPHvhnY\nX9IMqoTxTqo5zFvdAxwBLJZ0ADAB2ChpD0C2H5c0B9jcr1M9IiI6ZLv3cUiaAnyIqsN6Ql+57dcO\ntp/tzZJOAZZSja67yPZaSWcBvbaXAKcDF0iaT9VRfoJtlyuplkp6girpHNcSz99SJaA9JK0Hvmh7\nQTsnHRERO0724M3/kq4Bvgp8EPgT4Hhgo+0PNR/e0Ojp6XFvb2+nw4iIGFEkrbTd07+8ztAhe9v+\nEvBr29fb/iNg0NpGRESMXnWGHPl1eX5A0hup7rV4TnMhRUREN6uTOD5exqk6Hfg7qhv25g++S0RE\njFZ1Esf3bD8MPAy8puF4IiKiy9Xp47hB0jWSTpS0V+MRRUREV6szOu4LqQYj/B1gpaQrJR3beGQR\nEdGVak3IZPsm239GNXDhz4CdvTkwIiJGqO0mDkl7Sjpe0jepxox6gCqBRETEGFSnc3wV8HXgLNsr\nGo4nIiK6XJ3E8Vve3u3lERExZtTpHE/SiIiIJ9XqHI+IiOiTxBEREW2pc1XV35Yrq3aTdK2kjbmP\nIyJi7KpT43i97UeANwE/Al4A/N8mg4qIiO5VJ3H0XXn1RuDyMm5VRESMUXUux71S0h3AL4A/LTMC\n/rLZsCIiolvVuRz3DOAVQI/tXwOPA8c0HVhERHSnOp3jb6ea/W+LpDOBLwPPbzyyiIjoSnX6OD5q\n+1FJrwJeB3wJOL/ZsCIiolvVSRxbyvMbgYW2vwGMby6kiIjoZnUSx32SvgD8L+AqSbvX3A9JR0q6\nU9I6SWcM8Po0Scsk3SpptaS5pXy8pAslrZG0StLsln0OLeXrJH1ekmqdaUREDIk6CeAdwFLgDbYf\nAp5Djfs4JI0DzgWOAmYC8yTN7LfZmcBltg8B3gmcV8pPArB9EDAHOFtSX6znl9f3L48ja5xDREQM\nkTpXVf0c+A/gDZJOAfaxfU2NYx8GrLN9t+1NwKVsfTWWgT3L8iTg/rI8E7iuvP8G4CGgR9LzgD1t\nf7cMvvgPwFtqxBIREUOkzlVVpwFfAfYpjy9LOrXGsfcF7m1ZX1/KWi0AjpW0HrgK6DvuKuBoSbtK\nmgEcCuxX9l+/nWP2xX2ypF5JvRs3bqwRbkRE1FGnqepE4OW2/9L2XwKHU5qShsA8YLHtqcBc4OLS\nJLWIKin0Ap+lmnlwyzaPMgDbC2332O6ZMmXKEIUbERF17hwXT//S3lLKtuc+qlpCn6mlrNWJlD4K\n2yskTQAml+ap+U8GIN0I3AU8WI4z2DEjIqJBdWocFwLfk7RA0gLgu1T3cmzPzcD+kmZIGk/V+b2k\n3zb3AEcASDoAmABslLSHpImlfA6w2fbtth8AHpF0eLma6n8D/1IjloiIGCLbrXHY/oyk5cCrStF7\nbN9aY7/NpTN9KTAOWGR7raSzgF7bS4DTgQskzafqKD/BtiXtAyyV9ARVjeK4lkP/H2Ax8Azgm+UR\nERHDRIPNDFsuqV1r+8XDF9LQ6+npcW9vb6fDiIgYUSSttN3Tv3zQpirbW4A7JU1rLLKIiBhR6nSO\n7wWslXQT1ci4ANg+urGoIiKia9VJHB9tPIqIiBgxtpk4JL0AeK7t6/uVvwp4oOnAIiKiOw3Wx/FZ\n4JEByh8ur0VExBg0WOJ4ru01/QtL2fTGIoqIiK42WOJ49iCvPWOoA4mIiJFhsMTRK2mrMakkvRdY\n2VxIERHRzQa7quoDwD9LejdPJYoeqtn//qDpwCIiojttM3HY/gnwCkmvAQ4sxd+wfd2wRBYREV2p\nzlhVy4BlwxBLRESMALXmDo+IiOiTxBEREW1J4oiIiLYkcURERFuSOCIioi1JHBER0ZYkjoiIaEsS\nR0REtCWJIyIi2pLEERERbWk0cUg6UtKdktZJOmOA16dJWibpVkmrJc0t5btJukjSGkk/kPThln1O\nk3SbpLWSPtBk/BERsbU6c47vEEnjgHOBOcB64GZJS2zf3rLZmcBlts+XNBO4imqSqLcDu9s+SNIe\nwO2SLgGeCZwEHAZsAq6WdKXtdU2dR0REPF2TNY7DgHW277a9CbgUOKbfNgb2LMuTgPtbyidK2pVq\n0qhNVNPYHgB8z/bPbW8Grgfe2uA5REREP00mjn2Be1vW15eyVguAYyWtp6ptnFrKrwAeBx4A7gE+\nbftnwG3AqyXtXWoic4H9BnpzSSdL6pXUu3HjxiE6pYiI6HTn+Dxgse2pVEngYkm7UNVWtgDPB2YA\np0v6Lds/AD4FXANcDXy/bLcV2wtt99jumTJlyjCcSkTE2NBk4riPp9cGppayVicClwHYXgFMACYD\n7wKutv1r2xuAG6hmH8T2l2wfavv3gAeBuxo8h4iI6KfJxHEzsL+kGZLGA+8ElvTb5h7gCABJB1Al\njo2l/LWlfCJwOHBHWd+nPE+j6t/4xwbPISIi+mnsqirbmyWdAiwFxgGLbK+VdBbQa3sJcDpwgaT5\nVB3iJ9i2pHOBCyWtBQRcaHt1OfTXJO0N/Bp4n+2HmjqHiIjYmmx3OobG9fT0uLe3t9NhRESMKJJW\n2u7pX97pzvGIiBhhkjgiIqItSRwREdGWJI6IiGhLEkdERLQliSMiItqSxBEREW1J4oiIiLYkcURE\nRFuSOCIioi1JHBER0ZYkjoiIaEsSxyBWrIBPfKJ6joiISmPDqo90K1bAEUfApk0wfjxcey3MmtXp\nqCIiOi81jm1YvrxKGlu2VM/Ll3c6ooiI7pDEsQ2zZ1c1jXHjqufZszsdUUREd0hT1TbMmlU1Ty1f\nXiWNNFNFRFSSOAYxa1YSRkREf2mqioiItiRxREREWxpNHJKOlHSnpHWSzhjg9WmSlkm6VdJqSXNL\n+W6SLpK0RtIPJH24ZZ/5ktZKuk3SJZImNHkOERHxdI0lDknjgHOBo4CZwDxJM/ttdiZwme1DgHcC\n55XytwO72z4IOBT4Y0nTJe0LvB/osX0gMK7sFxERw6TJGsdhwDrbd9veBFwKHNNvGwN7luVJwP0t\n5RMl7Qo8A9gEPFJe2xV4Rnltj5Z9IiJiGDSZOPYF7m1ZX1/KWi0AjpW0HrgKOLWUXwE8DjwA3AN8\n2vbPbN8HfLqUPQA8bPuagd5c0smSeiX1bty4cYhOKSIiOn057jxgse2zJc0CLpZ0IFVtZQvwfGAv\n4N8kfRt4kKrWMgN4CLhc0rG2v9z/wLYXAgsBJG2U9ONhOaOhMxn4aaeDGGY557Eh5zxy/OZAhU0m\njvuA/VrWp5ayVicCRwLYXlE6uicD7wKutv1rYIOkG4Aeqias/7S9EUDSPwGvALZKHK1sT9n50xle\nknpt93Q6juGUcx4bcs4jX5NNVTcD+0uaIWk8VSf2kn7b3AMcASDpAGACsLGUv7aUTwQOB+4o5YdL\n2kOSyr4/aPAcIiKin8ZqHLY3SzoFWEp19dMi22slnQX02l4CnA5cIGk+VW3iBNuWdC5woaS1gIAL\nba8GkHQFcAuwGbiV0hwVERHDQ7Y7HUMMQNLJpZ9mzMg5jw0555EviSMiItqSIUciIqItSRwREdGW\nJI4uI2m/Mn7X7WVMrtM6HdNwkTSujFt2ZadjGQ6Sni3pCkl3lDHZRvUg/mNlnDlJiyRtkHRbS9lz\nJH1L0g/L816djHFnJXF0n83A6bZnUl2G/L4BxvgarU5jbF1e/Tmq+5VeDLyUUXzuY2ycucWU+9Na\nnAFca3t/4NqyPmIlcXQZ2w/YvqUsP0r1ZdJ/qJZRR9JU4I3AFzsdy3CQNAn4PeBLALY32X6os1E1\nbkyMM2f7O8DP+hUfA1xUli8C3jKsQQ2xJI4uJmk6cAjwvc5GMiw+C/w58ESnAxkmM6hudr2wNM99\nsdzsOiq1M87cKPVc2w+U5f8CntvJYHZWEkeXkvRM4GvAB2w/sr3tRzJJbwI22F7Z6ViG0a7A7wLn\nl2kFHmeEN18MprTp940z93yq0a+P7WxUneHqHogRfR9EEkcXkrQbVdL4iu1/6nQ8w+CVwNGSfkQ1\n/P5rJQ06/tgosB5Yb7uvNnkFVSIZrV5HGWeujEHXN87cWPETSc8DKM8bOhzPTkni6DJlDK4vAT+w\n/ZlOxzMcbH/Y9lTb06k6TK+zPap/jdr+L+BeSS8qRUcAt3cwpKaN9XHmlgDHl+XjgX/pYCw7LYmj\n+7wSOI7qV/f3y2Nup4OKRpwKfEXSauBg4G86HE9jSs2qb5y5NVTfPaNmCI5Wki4BVgAvkrRe0onA\nJ4E5kn5IVfv6ZCdj3FkZciQiItqSGkdERLQliSMiItqSxBEREW1J4oiIiLYkcURERFuSOKJtkh7r\ndAzbImm6pF+Uy5hvl/QP5YbKoX6fEySd0+Y+PZI+vwPvNV3Su3b2ONs49o8krZG0WtI1kn5jKI67\nsyR9QNIenY4jBpbEEV1H0ridPMR/2D4YOAiYCrxj56PaOZJ2td1r+/07sPt04MnEsRPH2ZbX2H4J\n0Av8Rd2dhuDfaTAfoBoIsbaG44kWSRyxwyTNlrS8ZU6Jr6hypKTL+213ZVl+vaQVkm6RdHkZk6vv\nl++nJN0CvF3S+0uNYbWkS8s2E8tcBzeVgQGPGSw+21uAmyijC5f5Pv6/pJvLcf+4lO8i6bxyDt+S\ndJWkP2yJa3JZ7pG0fIDP4c2Svldi+rak55byBZIulnQDcHG/z+Gqlhs8H5Z0fKlZ/Fv5bG6R1Dck\nxyeBV5dt5/c7znMkfb2cz3clvaTlvReVf5+7JdVJNN8BXlD2P19Sr6r5M/6q5Vz7/zudVD7PVZK+\n1ldLkLS4HOO75f1nl3h+IGlxy/G2+nsosT4fWCZpWTt/NzXOMYaC7TzyaOsBPFaeZwMPU/2q34Xq\nbtlXUQ3gdw8wsWx3PnAsMJnqy6mv/EPAX5blHwF/3vIe9wO7l+Vnl+e/AY7tKwPu6jtWy37TgdvK\n8gRgGfCSsn4ycGZZ3p3qF/YM4A+Bq8o5/AbwIPCHLXFNLss9wPKyfAJwTlnei6dupn0vcHZZXgCs\nBJ7R8nld2S/eQ4HVwCSqX9gTSvn+QO9A+7WuA38H/L+y/Frg+y3vfWM5z8nAfwO7DfBv2Xp+5wCf\nKsvPKc/jgOUtn2H/f6e9W5Y/DpxalhdTjTsmqsENH6GqAe5SPpOD2f7fQ19ctf9u8hiex65E7Jyb\nbK8HkPR9YLrtf5d0NfBmSVdQzbPx58DvAzOBGyQBjKdKNn2+2rK8mmo4jq8DXy9lr6caDPGDZX0C\nMI2txzz67RLLDOAbtle37P+SvtoE1Zf1/lTJ7nLbTwD/1fcrtw1Tga+qGrxuPPCfLa8tsf2LgXYq\nNZmLgXfYfljVHB3nSDoY2ET45EkAAALWSURBVAK8sMZ7vwp4G4Dt6yTtLWnP8to3bP8K+JWkDVRD\nea8f4BjLJG2h+szPLGXvkHQy1Y+A51H9u/V9jq3/TgdK+jhVIn8msLTltX+1bUlrgJ/YXlPOey1V\ngp/K4H8PfQ7fznZfHWCfaFASR+ysX7Usb+Gpv6lLgVOoJrTptf2oqv/137I9bxvHerxl+Y1UEx29\nGfiIpIOofr2+zfad24npP2wfXL6Yb5B0tO0lZf9Tbbd+uaHBxwLbzFNNutua6vTvgM/YXiJpNtWv\n/YHOqfU9x1F9RmfZ7ptidD7wE6rZAHcBfjlIXHVs69+mv9fY/mlLbDOADwIvs/1gaVpqPffWc1oM\nvMX2KkknUNWG+r//E/1ieaLEsoXB/x6eDGk72w34GUdz0scRTbmeapjwk6i+IAG+C7xSUl87+kRJ\nW/2qlrQLsJ/tZVTNEpN46tfsqSUBIemQwQIoX4ZnAB8uRUuBP1W5ykrSC1VNnnQD8LbS1/Fcnv7l\n9yOq5iQov+wHMAm4rywfv41t+vsksNr2pS1lk4AHSs3nOKpmIoBHgWdt4zj/Bry7nM9s4Kfe+flb\n9qT6Mn64fB5HDbLts4AHymf67jbfZ7C/h9ZzrvV3E8MniSMa4apj+kqqL50rS9lGqr6BS1SNCLsC\nePEAu48DvlyaOG4FPu9qWtWPAbsBq0tzx8dqhPJ1YA9Jr6aalvZ24BZJtwFfoPrl+zWqJpzbgS9T\njeD6cNn/r4DPSeql+oU8kAXA5ZJWAj/dxjb9fRB4fUsH+dHAecDxklZRfS59v6RXA1tKB/T8Ad77\n0PJ5fpL6iWubbK+i+tzvAP6RKrFuy0epZqi8oWzfzvsM9vewELha0rI2/m5imGR03AiqGRdtPyZp\nb6orsV7pas6MiOgnfRwRlSslPZuq4/VjSRoR25YaR0REtCV9HBER0ZYkjoiIaEsSR0REtCWJIyIi\n2pLEERERbfkf5xWmLpCTW/IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npKJKQxFZWfw",
        "colab_type": "text"
      },
      "source": [
        "# SVM on Imdb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNN5OaScZaWH",
        "colab_type": "code",
        "outputId": "efc7956c-265a-4036-fc23-3883d45ff273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Default parameters\n",
        "# SKLearn default logistic regression\n",
        "# Penalty: l2\n",
        "# loss: squared hinge\n",
        "# Inverse reg strength (C): 1.0\n",
        "# Dual: True\n",
        "\n",
        "SVC_imdb_default_clf = Pipeline([\n",
        "                           ('vect', CountVectorizer()),\n",
        "                           ('tfidf', TfidfTransformer()),\n",
        "                           ('clf', LinearSVC()),\n",
        "])\n",
        "\n",
        "SVC_imdb_default_results = cross_validate(SVC_imdb_default_clf, twentyTrain.data, twentyTrain.target, return_train_score=True, cv=5, n_jobs=-1, verbose=1)\n",
        "print('CV accuracy: ', np.mean(SVC_imdb_default_results['test_score']))\n",
        "print('Mean fit time: ', np.mean(SVC_imdb_default_results['fit_time']))\n",
        "print('Train acc: ', np.mean(SVC_imdb_default_results['train_score']))\n",
        "\n",
        "start = time.time()\n",
        "SVC_imdb_default_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "print('Train time:', time.time() - start)\n",
        "# Training accuracy\n",
        "trainPredictions = SVC_imdb_default_clf.predict(imdbTrain.data)\n",
        "print('Train accuracy: ', accuracy_score(imdbTrain.target, trainPredictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   17.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CV accuracy:  0.7610048318918143\n",
            "Mean fit time:  3.7774492740631103\n",
            "Train acc:  0.973462081835768\n",
            "Train time: 3.9543659687042236\n",
            "Train accuracy:  0.98996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyy6F82Z4s9V",
        "colab_type": "code",
        "outputId": "babc12d2-5a01-4923-cc24-671a03cf4962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Grid search SVC on Imdb\n",
        "# dual = False, loss=squared_hinge (loss=hinge does not work with dual=False)\n",
        "\n",
        "# Build pipeline\n",
        "SVC_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LinearSVC(dual=False, loss='squared_hinge')),\n",
        "])\n",
        "# 'clf__penalty': ('l2', 'l1'),\n",
        "# Params for main grid search\n",
        "params = {'clf__penalty': ('l2','l1'),\n",
        "          'clf__C': (0.01, 0.1, 0.5, 1.0, 2, 5, 10, 100)}\n",
        "\n",
        "SVC_gs_clf = GridSearchCV(SVC_clf, params, n_jobs=-1, return_train_score=True)\n",
        "SVC_gs_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "# Figuring out what these params are\n",
        "# print(SVC_gs_clf.cv_results_)\n",
        "# print(SVC_gs_clf.best_score_)\n",
        "# print(SVC_gs_clf.best_params_)\n",
        "# print(SVC_gs_clf.best_index_)\n",
        "# print(SVC_gs_clf.cv_results_['mean_test_score'][SVC_gs_clf.best_index_])\n",
        "\n",
        "for param_name in sorted(params.keys()):\n",
        "  print(\"%s : %r\" % (param_name, SVC_gs_clf.best_params_[param_name]))\n",
        "print('Train time for best params:', SVC_gs_clf.cv_results_['mean_fit_time'][SVC_gs_clf.best_index_])\n",
        "print('Train acc for best params:', SVC_gs_clf.cv_results_['mean_train_score'][SVC_gs_clf.best_index_])\n",
        "print('CV acc for best params:', SVC_gs_clf.best_score_)\n",
        "\n",
        "# Check how the best performs:\n",
        "SVC_best_clf = Pipeline([\n",
        "                         ('vect', CountVectorizer()),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('clf', LinearSVC(penalty=SVC_gs_clf.best_params_['clf__penalty'],\n",
        "                                           loss='squared_hinge',\n",
        "                                           dual=False,\n",
        "                                           C=SVC_gs_clf.best_params_['clf__C']))\n",
        "])\n",
        "\n",
        "start = time.time()\n",
        "SVC_best_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = SVC_best_clf.predict(imdbTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, imdbTrain.target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clf__C : 0.5\n",
            "clf__penalty : 'l2'\n",
            "Train time for best params: 6.828944826126099\n",
            "Train acc for best params: 0.98001\n",
            "CV acc for best params: 0.8950799999999999\n",
            "Train time: 5.137102127075195\n",
            "Train acc: 0.97808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFMLiz3XaTmz",
        "colab_type": "code",
        "outputId": "26dede7c-4540-490d-b147-e20d399054da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Grid search SVC on Imdb\n",
        "# dual = True, penalty=l2\n",
        "\n",
        "# Build pipeline\n",
        "SVC_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LinearSVC(dual=True, penalty='l2'))\n",
        "])\n",
        "# Params for main grid search\n",
        "params = {'clf__loss': ('hinge','squared_hinge'),\n",
        "          'clf__C': (0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10, 100)}\n",
        "\n",
        "SVC_gs_clf = GridSearchCV(SVC_clf, params, n_jobs=-1, return_train_score=True)\n",
        "SVC_gs_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "for param_name in sorted(params.keys()):\n",
        "  print(\"%s : %r\" % (param_name, SVC_gs_clf.best_params_[param_name]))\n",
        "print('Train time for best params:', SVC_gs_clf.cv_results_['mean_fit_time'][SVC_gs_clf.best_index_])\n",
        "print('Train acc for best params:', SVC_gs_clf.cv_results_['mean_train_score'][SVC_gs_clf.best_index_])\n",
        "print('CV acc for best params:', SVC_gs_clf.best_score_)\n",
        "\n",
        "# Check how the best performs:\n",
        "SVC_best_clf = Pipeline([\n",
        "                         ('vect', CountVectorizer()),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('clf', LinearSVC(penalty='l2',\n",
        "                                           loss=SVC_gs_clf.best_params_['clf__loss'],\n",
        "                                           dual=True,\n",
        "                                           C=SVC_gs_clf.best_params_['clf__C']))\n",
        "])\n",
        "\n",
        "start = time.time()\n",
        "SVC_best_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = SVC_best_clf.predict(imdbTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, imdbTrain.target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clf__C : 0.5\n",
            "clf__loss : 'squared_hinge'\n",
            "Train time for best params: 5.540150880813599\n",
            "Train acc for best params: 0.98001\n",
            "CV acc for best params: 0.8950799999999999\n",
            "Train time: 3.9649925231933594\n",
            "Train acc: 0.97808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAyFIfKT8QJ0",
        "colab_type": "code",
        "outputId": "6b4f8298-7e94-4c2e-cc84-c1a1c718cc3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Fine search for inverse reg param with best params otherwise\n",
        "# penalty=l2, dual=true since results l2 always on top, and results don't change with dual, only train time\n",
        "# Build pipeline\n",
        "SVC_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LinearSVC(dual=True, penalty='l2'))\n",
        "])\n",
        "# Params for main grid search\n",
        "params = {'clf__loss': ('hinge','squared_hinge'),\n",
        "          'clf__C': (0.2, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.7, 0.8)}\n",
        "\n",
        "SVC_gs_clf = GridSearchCV(SVC_clf, params, n_jobs=-1, return_train_score=True)\n",
        "SVC_gs_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "for param_name in sorted(params.keys()):\n",
        "  print(\"%s : %r\" % (param_name, SVC_gs_clf.best_params_[param_name]))\n",
        "print('Train time for best params:', SVC_gs_clf.cv_results_['mean_fit_time'][SVC_gs_clf.best_index_])\n",
        "print('Train acc for best params:', SVC_gs_clf.cv_results_['mean_train_score'][SVC_gs_clf.best_index_])\n",
        "print('CV acc for best params:', SVC_gs_clf.best_score_)\n",
        "\n",
        "# Check how the best performs:\n",
        "SVC_best_clf = Pipeline([\n",
        "                         ('vect', CountVectorizer()),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('clf', LinearSVC(penalty='l2',\n",
        "                                           loss=SVC_gs_clf.best_params_['clf__loss'],\n",
        "                                           dual=True,\n",
        "                                           C=SVC_gs_clf.best_params_['clf__C']))\n",
        "])\n",
        "\n",
        "start = time.time()\n",
        "SVC_best_clf.fit(imdbTrain.data, imdbTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = SVC_best_clf.predict(imdbTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, imdbTrain.target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clf__C : 0.55\n",
            "clf__loss : 'squared_hinge'\n",
            "Train time for best params: 5.555875682830811\n",
            "Train acc for best params: 0.9821100000000001\n",
            "CV acc for best params: 0.89544\n",
            "Train time: 3.727783203125\n",
            "Train acc: 0.97996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR2SBQsk8kLl",
        "colab_type": "code",
        "outputId": "1883fa52-bbba-4daa-de8f-60005afbfa93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "source": [
        "# Looking at CV results mean acc for all C\n",
        "# Made a plot to show why its not worth tuning C anymore.\n",
        "%matplotlib inline \n",
        "cs = []\n",
        "cvAccs = []\n",
        "for p, r in zip(SVC_gs_clf.cv_results_['params'], SVC_gs_clf.cv_results_['mean_test_score']):\n",
        "  if p['clf__loss'] != 'hinge':\n",
        "    print(p,r)\n",
        "    cs.append(p['clf__C'])\n",
        "    cvAccs.append(r)\n",
        "fig = plt.figure()\n",
        "plt.plot(cs, cvAccs, 'b.')\n",
        "plt.xlabel('Inverse Regularization Parameter')\n",
        "plt.ylabel('Cross validated accuracy')\n",
        "plt.savefig('imdbCTunePlot', dpi=400)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'clf__C': 0.2, 'clf__loss': 'squared_hinge'} 0.89448\n",
            "{'clf__C': 0.3, 'clf__loss': 'squared_hinge'} 0.8952\n",
            "{'clf__C': 0.35, 'clf__loss': 'squared_hinge'} 0.89512\n",
            "{'clf__C': 0.4, 'clf__loss': 'squared_hinge'} 0.8950400000000001\n",
            "{'clf__C': 0.45, 'clf__loss': 'squared_hinge'} 0.89528\n",
            "{'clf__C': 0.5, 'clf__loss': 'squared_hinge'} 0.8950799999999999\n",
            "{'clf__C': 0.55, 'clf__loss': 'squared_hinge'} 0.89544\n",
            "{'clf__C': 0.6, 'clf__loss': 'squared_hinge'} 0.8952\n",
            "{'clf__C': 0.7, 'clf__loss': 'squared_hinge'} 0.89416\n",
            "{'clf__C': 0.8, 'clf__loss': 'squared_hinge'} 0.8935600000000001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEHCAYAAAB4POvAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntQ5NnwY5uU7",
        "colab_type": "code",
        "outputId": "0d7f1dbe-b675-47d6-e8a3-0b8ef61d7dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Tuning Count Vec and tfidf, imdb\n",
        "SVC_imdb_feat_tune = Pipeline([\n",
        "                        ('vect', CountVectorizer()),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('clf', LinearSVC(penalty='l2', dual=True, loss='squared_hinge'))                            \n",
        "])\n",
        "params = {'vect__ngram_range': ((1,1), (1,2)),\n",
        "         'vect__max_df': (0.2, 0.4, 0.6, 0.8, 1.0),\n",
        "          'tfidf__sublinear_tf': (True, False),\n",
        "         'clf__C': (0.01, 0.1, 1.0, 10, 20)}\n",
        "\n",
        "SVC_imdb_feat_tune_gs = GridSearchCV(SVC_imdb_feat_tune, params, return_train_score=True)\n",
        "SVC_imdb_feat_tune_gs.fit(imdbTrain.data, imdbTrain.target) \n",
        "\n",
        "for param_name in sorted(params.keys()):\n",
        "  print(\"%s : %r\" % (param_name, SVC_imdb_feat_tune_gs.best_params_[param_name]))\n",
        "\n",
        "print('Train time for best params:', SVC_imdb_feat_tune_gs.cv_results_['mean_fit_time'][SVC_imdb_feat_tune_gs.best_index_])\n",
        "print('Train acc for best params:', SVC_imdb_feat_tune_gs.cv_results_['mean_train_score'][SVC_imdb_feat_tune_gs.best_index_])\n",
        "print('CV acc for best params:', SVC_imdb_feat_tune_gs.best_score_)\n",
        "\n",
        "# Check how the best performs:\n",
        "SVC_imdb_feat_tune_best = Pipeline([\n",
        "                         ('vect', CountVectorizer(ngram_range=SVC_imdb_feat_tune_gs.best_params_['vect__ngram_range'],\n",
        "                                                  max_df=SVC_imdb_feat_tune_gs.best_params_['vect__max_df'])),\n",
        "                         ('tfidf', TfidfTransformer(sublinear_tf=SVC_imdb_feat_tune_gs.best_params_['tfidf__sublinear_tf'])),\n",
        "                         ('clf', LinearSVC(penalty='l2',\n",
        "                                           loss='squared_hinge',\n",
        "                                           dual=True,\n",
        "                                           C=SVC_imdb_feat_tune_gs.best_params_['clf__C']))\n",
        "])\n",
        "\n",
        "start = time.time()\n",
        "SVC_imdb_feat_tune_best.fit(imdbTrain.data, imdbTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = SVC_imdb_feat_tune_best.predict(imdbTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, imdbTrain.target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clf__C : 1.0\n",
            "tfidf__sublinear_tf : True\n",
            "vect__max_df : 0.2\n",
            "vect__ngram_range : (1, 2)\n",
            "Train time for best params: 14.008985948562621\n",
            "Train acc for best params: 0.9999600000000001\n",
            "CV acc for best params: 0.9110799999999999\n",
            "Train time: 17.62760066986084\n",
            "Train acc: 0.99996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjhLb0KV_Ixv",
        "colab_type": "code",
        "outputId": "c80c90ee-9d67-46c1-d08e-57cfe72b262c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Using the best model with feature selection on the test set\n",
        "SVC_imdb_best = Pipeline([\n",
        "                         ('vect', CountVectorizer(max_df=0.2, ngram_range=(1,2))),\n",
        "                         ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
        "                         ('clf', LinearSVC(penalty='l2', dual=True, loss='squared_hinge', C=1.0)) \n",
        "])\n",
        "SVC_imdb_best.fit(imdbTrain.data, imdbTrain.target)\n",
        "imdbTestPreds = SVC_imdb_best.predict(imdbTest.data)\n",
        "print('Test acc:', accuracy_score(imdbTestPreds, imdbTest.target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test acc: 0.90664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X9_n308ByK0P"
      },
      "source": [
        "# Studying new feature design, imdb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c6715201-14f6-43fc-b214-98e692d36223",
        "id": "qd39tFzeyK0S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Performing first two steps of pipeline separately to be able to study them.\n",
        "# First, look at new feature design\n",
        "CountVec = CountVectorizer(max_df=0.2, ngram_range=(1,2))\n",
        "imdbTrain_count = CountVec.fit_transform(imdbTrain.data)\n",
        "tfidfVec = TfidfTransformer(sublinear_tf=True).fit(imdbTrain_count)\n",
        "imdbTrain_tfidf = tfidfVec.transform(imdbTrain_count)\n",
        "print('New design shape:', imdbTrain_tfidf.shape)\n",
        "# Now, look at default\n",
        "CountVec_def = CountVectorizer()\n",
        "imdbTrain_count_def = CountVec_def.fit_transform(imdbTrain.data)\n",
        "tfidfVec_def = TfidfTransformer().fit(imdbTrain_count_def)\n",
        "imdbTrain_tfidf_def = tfidfVec_def.transform(imdbTrain_count_def)\n",
        "print('Default shape:', imdbTrain_tfidf_def.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New design shape: (25000, 1513704)\n",
            "Default shape: (25000, 74849)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfMhEYLJAIrN",
        "colab_type": "text"
      },
      "source": [
        "# Load 20 Newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q5k-mIwLFqe",
        "colab_type": "code",
        "outputId": "31eb5a6f-49f0-4ff6-f6e6-249097178e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Load 20 newsgroups\n",
        "twentyTrain = fetch_20newsgroups(subset='train', remove=(['headers', 'footers', 'quotes']))\n",
        "twentyTest = fetch_20newsgroups(subset='test', remove=(['headers', 'footers', 'quotes']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSOxK6nJqNQp",
        "colab_type": "code",
        "outputId": "cfb32465-9ba1-4c77-97e7-f6c62c21b8a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Create validation set for quick tests before running CV or grid search strategies by splitting the train set\n",
        "# Control random state so for all group members split will be the same - good for comparing accuracies\n",
        "x20Train, x20Val, y20Train, y20Val = train_test_split(twentyTrain.data, twentyTrain.target, test_size=0.2, random_state=1)\n",
        "print(y20Train.shape, y20Val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9051,) (2263,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUWVTdZ7K_JQ",
        "colab_type": "text"
      },
      "source": [
        "# LR on 20 newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_SthbNGO1_O",
        "colab_type": "code",
        "outputId": "77f1dc1d-7aee-43e5-8272-1953c88f7b75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Default LR parameters\n",
        "# Also increased max_iters\n",
        "\n",
        "lbfgs_default_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LogisticRegression(max_iter=1000, verbose=True)),\n",
        "])\n",
        "\n",
        "results = cross_validate(lbfgs_default_clf, twentyTrain.data, twentyTrain.target, return_train_score=True, cv=5, n_jobs=-1, verbose=1)\n",
        "print('CV accuracy: ', np.mean(results['test_score']))\n",
        "print('Mean fit time: ', np.mean(results['fit_time']))\n",
        "print('Train acc: ', np.mean(results['train_score']))\n",
        "\n",
        "# Get train time with full dataset\n",
        "start = time.time()\n",
        "lbfgs_default_clf.fit(twentyTrain.data, twentyTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = lbfgs_default_clf.predict(twentyTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, twentyTrain.target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CV accuracy:  0.7248545294639129\n",
            "Mean fit time:  41.89269018173218\n",
            "Train acc:  0.910243944402449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   34.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train time: 36.390690326690674\n",
            "Train acc: 0.907371398267633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6InQQ6Mo5Mq",
        "colab_type": "code",
        "outputId": "d1f96d17-a2d9-4ce1-99c7-fd69c6287716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Chose lbfgs solver (all solvers essentially the same on Imdb, and this one has a real multiclass classification option unlike liblinear)\n",
        "# Group 1: lbfgs, penalty = none\n",
        "# Penalty = none\n",
        "\n",
        "lbfgs_none_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LogisticRegression(solver='lbfgs', penalty='none', max_iter=1000, verbose=True, n_jobs=-1)),\n",
        "])\n",
        "\n",
        "results = cross_validate(lbfgs_none_clf, twentyTrain.data, twentyTrain.target, return_train_score=True, cv=5, n_jobs=-1, verbose=1)\n",
        "print('CV accuracy: ', np.mean(results['test_score']))\n",
        "print('Mean fit time: ', np.mean(results['fit_time']))\n",
        "print('Train acc: ', np.mean(results['train_score']))\n",
        "\n",
        "# Get train time with full dataset\n",
        "start = time.time()\n",
        "lbfgs_none_clf.fit(twentyTrain.data, twentyTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = lbfgs_none_clf.predict(twentyTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, twentyTrain.target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  9.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CV accuracy:  0.722468589968247\n",
            "Mean fit time:  195.81416606903076\n",
            "Train acc:  0.974854163911254\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train time: 108.85000467300415\n",
            "Train acc: 0.9747215838783808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a63845fb-9576-450c-90c1-18e49ccf496c",
        "id": "_HzcUw1a5Wsy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "# Chose lbfgs solver (all solvers essentially the same on Imdb, and this one has a real multiclass classification option unlike liblinear)\n",
        "# Group 1: lbfgs, penalty = l2\n",
        "\n",
        "lbfgs_l2_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LogisticRegression(solver='lbfgs', penalty='l2', max_iter=1000, verbose=True, n_jobs=-1))\n",
        "])\n",
        "params = {'clf__C': (10,11,12,13,14,15,16,17,18,19,20,25,30,50,100)}\n",
        "\n",
        "lbfgs_l2_gs_clf = GridSearchCV(lbfgs_l2_clf, params, n_jobs=-1, return_train_score=True)\n",
        "lbfgs_l2_gs_clf.fit(twentyTrain.data, twentyTrain.target)\n",
        "\n",
        "print(\"C: \", lbfgs_l2_gs_clf.best_params_['clf__C'])\n",
        "print('Train time for best params:', lbfgs_l2_gs_clf.cv_results_['mean_fit_time'][lbfgs_l2_gs_clf.best_index_])\n",
        "print('Train acc for best params:', lbfgs_l2_gs_clf.cv_results_['mean_train_score'][lbfgs_l2_gs_clf.best_index_])\n",
        "print('CV acc for best params:', lbfgs_l2_gs_clf.best_score_)\n",
        "\n",
        "# Get train time with full dataset\n",
        "lbfgs_l2_best = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LogisticRegression(solver='lbfgs', penalty='l2', max_iter=1000, verbose=True, n_jobs=-1, C=lbfgs_l2_gs_clf.best_params_['clf__C'])),\n",
        "])\n",
        "start = time.time()\n",
        "lbfgs_l2_best.fit(twentyTrain.data, twentyTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = lbfgs_l2_best.predict(twentyTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, twentyTrain.target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "C:  17\n",
            "Train time for best params: 108.45113377571106\n",
            "Train acc for best params: 0.9744785245761817\n",
            "CV acc for best params: 0.749691242620982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train time: 106.6109721660614\n",
            "Train acc: 0.9747215838783808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfvdnL3brhlX",
        "colab_type": "code",
        "outputId": "292ef851-b8d2-4d28-ea8c-de3b62ad0a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Get train time with full dataset, group 1\n",
        "# Also get test accuracy\n",
        "lbfgs_l2_best = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LogisticRegression(solver='lbfgs', penalty='l2', max_iter=1000, verbose=True, n_jobs=-1, C=17))\n",
        "])\n",
        "start = time.time()\n",
        "lbfgs_l2_best.fit(twentyTrain.data, twentyTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = lbfgs_l2_best.predict(twentyTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, twentyTrain.target))\n",
        "\n",
        "LR20BestPreds = lbfgs_l2_best.predict(twentyTest.data)\n",
        "print('Best LR on 20 acc: ', accuracy_score(twentyTest.target, LR20BestPreds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train time: 95.363520860672\n",
            "Train acc: 0.9743680395969595\n",
            "Best LR on 20 acc:  0.6826872012745618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guYI_nbNr3MK",
        "colab_type": "code",
        "outputId": "aac8fc92-0cb9-4a10-9b48-489b9cd87d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "# Looking at CV results mean acc for all C\n",
        "# Made a plot to show why its not worth tuning C anymore.\n",
        "%matplotlib inline \n",
        "cs = []\n",
        "cvAccs = []\n",
        "for p, r in zip(lbfgs_l2_gs_clf.cv_results_['params'], lbfgs_l2_gs_clf.cv_results_['mean_test_score']):\n",
        "    cs.append(p['clf__C'])\n",
        "    cvAccs.append(r)\n",
        "fig = plt.figure()\n",
        "plt.plot(cs, cvAccs, 'b.')\n",
        "plt.xlabel('Inverse Regularization Parameter')\n",
        "plt.xscale('log')\n",
        "plt.ylabel('Cross validated accuracy')\n",
        "plt.savefig('20CTunePlotlbfgsl2', dpi=400)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-d2c1c5fd6061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcvAccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbfgs_l2_gs_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbfgs_l2_gs_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf__C'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcvAccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lbfgs_l2_gs_clf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnfG1Aspr8dS",
        "colab_type": "code",
        "outputId": "c47b0422-8827-4ce2-ccc6-10e58074ad2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# Wanted to see if liblinear could do better on this,\n",
        "# But it's actually training 20 classifiers (one versus rest, so seeing results not so simple)\n",
        "\n",
        "liblin_l2_True_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LogisticRegression(solver='liblinear', penalty='l2', dual=True, max_iter=1000, verbose=True))\n",
        "])\n",
        "# params = {'clf__C': (0.1, 1.0, 10, 20)}\n",
        "params = {'clf__C': (15,19)}\n",
        "# params = {'clf__C': (3.0,5.0,6.0,7.0,8.0,8.5,9.0.9.5,10.5,11,11.5,12,13,14,15,17,19)}\n",
        "\n",
        "liblin_l2_True_gs_clf = GridSearchCV(liblin_l2_True_clf, params, return_train_score=True)\n",
        "liblin_l2_True_gs_clf.fit(twentyTrain.data, twentyTrain.target)\n",
        "\n",
        "print(\"C: \", liblin_l2_True_gs_clf.best_params_['clf__C'])\n",
        "print('Train time for best params:', liblin_l2_True_gs_clf.cv_results_['mean_fit_time'][liblin_l2_True_gs_clf.best_index_])\n",
        "print('Train acc for best params:', liblin_l2_True_gs_clf.cv_results_['mean_train_score'][liblin_l2_True_gs_clf.best_index_])\n",
        "print('CV acc for best params:', liblin_l2_True_gs_clf.best_score_)\n",
        "\n",
        "# Get train time with full dataset\n",
        "liblinear_l2_True_best = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LogisticRegression(solver='liblinear', penalty='l2', dual=True, max_iter=1000, verbose=True, C=liblin_l2_True_gs_clf.best_params_['clf__C'])),\n",
        "])\n",
        "start = time.time()\n",
        "liblinear_l2_True_best.fit(twentyTrain.data, twentyTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = liblinear_l2_True_best.predict(twentyTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, twentyTrain.target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Train time for best params: 6.879440593719482\n",
            "Train acc for best params: 0.9741470743705831\n",
            "CV acc for best params: 0.7532264901914588\n",
            "[LibLinear]Train time: 9.046155452728271\n",
            "Train acc: 0.9740144953155383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttFme8qVxVL2",
        "colab_type": "code",
        "outputId": "72c93a7c-6d2b-4b9e-f94f-89dc93283342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(liblin_l2_True_gs_clf.best_params_['clf__C'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHnmZwrSOrcE",
        "colab_type": "text"
      },
      "source": [
        "# SVC on 20 newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpoGRb88b659",
        "colab_type": "code",
        "outputId": "c7f2a0a6-799c-4533-836b-1f3461abff34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# SKLearn default SVC on 20 newsgroups\n",
        "# Penalty: l2\n",
        "# loss: squared hinge\n",
        "# Inverse reg strength (C): 1.0\n",
        "# Dual: True\n",
        "\n",
        "SVC_20_default_clf = Pipeline([\n",
        "                           ('vect', CountVectorizer()),\n",
        "                           ('tfidf', TfidfTransformer()),\n",
        "                           ('clf', LinearSVC()),\n",
        "])\n",
        "\n",
        "SVC_20_default_results = cross_validate(SVC_20_default_clf, twentyTrain.data, twentyTrain.target, return_train_score=True, cv=5, n_jobs=-1, verbose=1)\n",
        "print('CV accuracy: ', np.mean(SVC_20_default_results['test_score']))\n",
        "print('Mean fit time: ', np.mean(SVC_20_default_results['fit_time']))\n",
        "print('Train acc: ', np.mean(SVC_20_default_results['train_score']))\n",
        "\n",
        "start = time.time()\n",
        "SVC_20_default_clf.fit(twentyTrain.data, twentyTrain.target)\n",
        "print('Train time:', time.time() - start)\n",
        "# Training accuracy\n",
        "trainPredictions = SVC_20_default_clf.predict(twentyTrain.data)\n",
        "print('Train accuracy: ', accuracy_score(twentyTrain.target, trainPredictions))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   17.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CV accuracy:  0.7610048318918143\n",
            "Mean fit time:  3.8404488563537598\n",
            "Train acc:  0.973462081835768\n",
            "Train time: 3.057391881942749\n",
            "Train accuracy:  0.9725119321194979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYu42E4lFH5J",
        "colab_type": "code",
        "outputId": "27d67596-9dfd-414f-c22c-d6eecffa0655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Group 1:\n",
        "# dual = False, loss = squared_hinge\n",
        "# Max iter a bit higher to prevent time consuming hit the end of loop criteria\n",
        "# Tune the rest\n",
        "# Build pipeline\n",
        "\n",
        "SVC_20_G1 = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LinearSVC(dual=False, loss='squared_hinge', max_iter=500)),\n",
        "])\n",
        "\n",
        "# Params for main grid search\n",
        "params = {'clf__penalty': ('l2','l1'),\n",
        "          'clf__C': (0.01, 0.1, 1.0, 10, 100)}\n",
        "\n",
        "SVC_20_G1_gs = GridSearchCV(SVC_20_G1, params, n_jobs=-1, return_train_score=True)\n",
        "SVC_20_G1_gs.fit(twentyTrain.data, twentyTrain.target)\n",
        "\n",
        "for param_name in sorted(params.keys()):\n",
        "  print(\"%s : %r\" % (param_name, SVC_20_G1_gs.best_params_[param_name]))\n",
        "print('Train time for best params:', SVC_20_G1_gs.cv_results_['mean_fit_time'][SVC_20_G1_gs.best_index_])\n",
        "print('Train acc for best params:', SVC_20_G1_gs.cv_results_['mean_train_score'][SVC_20_G1_gs.best_index_])\n",
        "print('CV acc for best params:', SVC_20_G1_gs.best_score_)\n",
        "\n",
        "# Check how the best performs:\n",
        "SVC_best_clf = Pipeline([\n",
        "                         ('vect', CountVectorizer()),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('clf', LinearSVC(penalty=SVC_20_G1_gs.best_params_['clf__penalty'],\n",
        "                                           loss='squared_hinge',\n",
        "                                           dual=False,\n",
        "                                           C=SVC_20_G1_gs.best_params_['clf__C']))\n",
        "])\n",
        "\n",
        "start = time.time()\n",
        "SVC_best_clf.fit(twentyTrain.data, twentyTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = SVC_best_clf.predict(twentyTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, twentyTrain.target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clf__C : 1.0\n",
            "clf__penalty : 'l2'\n",
            "Train time for best params: 7.110265398025513\n",
            "Train acc for best params: 0.973462081835768\n",
            "CV acc for best params: 0.7610048318918143\n",
            "Train time: 6.7272725105285645\n",
            "Train acc: 0.9725119321194979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llgvF2zwGgom",
        "colab_type": "code",
        "outputId": "428c4471-d291-4f4d-beab-0feebae2b1b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# Grid search SVC on 20 newsgroups\n",
        "# Group 2\n",
        "# dual = True, penalty=l2\n",
        "\n",
        "# Build pipeline\n",
        "SVC_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LinearSVC(dual=True, penalty='l2'))\n",
        "])\n",
        "# Params for main grid search\n",
        "params = {'clf__loss': ('hinge','squared_hinge'),\n",
        "          'clf__C': (0.01, 0.1, 1.0, 10, 100)}\n",
        "\n",
        "SVC_gs_clf = GridSearchCV(SVC_clf, params, n_jobs=-1, return_train_score=True, verbose=1)\n",
        "SVC_gs_clf.fit(twentyTrain.data, twentyTrain.target)\n",
        "for param_name in sorted(params.keys()):\n",
        "  print(\"%s : %r\" % (param_name, SVC_gs_clf.best_params_[param_name]))\n",
        "print('Train time for best params:', SVC_gs_clf.cv_results_['mean_fit_time'][SVC_gs_clf.best_index_])\n",
        "print('Train acc for best params:', SVC_gs_clf.cv_results_['mean_train_score'][SVC_gs_clf.best_index_])\n",
        "print('CV acc for best params:', SVC_gs_clf.best_score_)\n",
        "\n",
        "# Check how the best performs:\n",
        "SVC_best_clf = Pipeline([\n",
        "                         ('vect', CountVectorizer()),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('clf', LinearSVC(penalty='l2',\n",
        "                                           loss=SVC_gs_clf.best_params_['clf__loss'],\n",
        "                                           dual=True,\n",
        "                                           C=SVC_gs_clf.best_params_['clf__C']))\n",
        "])\n",
        "\n",
        "start = time.time()\n",
        "SVC_best_clf.fit(twentyTrain.data, twentyTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = SVC_best_clf.predict(twentyTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, twentyTrain.target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  5.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "clf__C : 1.0\n",
            "clf__loss : 'squared_hinge'\n",
            "Train time for best params: 3.9801932334899903\n",
            "Train acc for best params: 0.973462081835768\n",
            "CV acc for best params: 0.7610048318918143\n",
            "Train time: 2.9943928718566895\n",
            "Train acc: 0.9725119321194979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkj2BgAuORDk",
        "colab_type": "code",
        "outputId": "d77097a9-6aae-4a5f-bec6-a2456fdb6faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Build pipeline\n",
        "SVC_20_fine = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LinearSVC(dual=True, penalty='l2', loss='squared_hinge'))\n",
        "])\n",
        "# Params for main grid search\n",
        "params = {'clf__C': (0.2, 0.4, 0.6, 0.8, 0.85, 0.9, 0.95, 1.05, 1.1, 1.2, 1.5, 2, 3, 5, 7)}\n",
        "\n",
        "SVC_20_fine_gs = GridSearchCV(SVC_20_fine, params, n_jobs=-1, return_train_score=True, verbose=1)\n",
        "SVC_20_fine_gs.fit(twentyTrain.data, twentyTrain.target)\n",
        "for param_name in sorted(params.keys()):\n",
        "  print(\"%s : %r\" % (param_name, SVC_20_fine_gs.best_params_[param_name]))\n",
        "print('Train time for best params:', SVC_20_fine_gs.cv_results_['mean_fit_time'][SVC_20_fine_gs.best_index_])\n",
        "print('Train acc for best params:', SVC_20_fine_gs.cv_results_['mean_train_score'][SVC_20_fine_gs.best_index_])\n",
        "print('CV acc for best params:', SVC_20_fine_gs.best_score_)\n",
        "\n",
        "# Check how the best performs:\n",
        "SVC_20_fine_best = Pipeline([\n",
        "                         ('vect', CountVectorizer()),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('clf', LinearSVC(penalty='l2',\n",
        "                                           loss='squared_hinge',\n",
        "                                           dual=True,\n",
        "                                           C=SVC_20_fine_gs.best_params_['clf__C']))\n",
        "])\n",
        "\n",
        "start = time.time()\n",
        "SVC_20_fine_best.fit(twentyTrain.data, twentyTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = SVC_20_fine_best.predict(twentyTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, twentyTrain.target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.5min\n",
            "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:  4.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "clf__C : 0.6\n",
            "Train time for best params: 3.7636682033538817\n",
            "Train acc for best params: 0.9701476139554457\n",
            "CV acc for best params: 0.7647169922635814\n",
            "Train time: 2.7592933177948\n",
            "Train acc: 0.9687113310942196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC0amah9x2x6",
        "colab_type": "code",
        "outputId": "3f425bca-2fd5-4acc-fd3e-43065f126217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        }
      },
      "source": [
        "# Looking at CV results mean acc for all C\n",
        "# Made a plot to show why its not worth tuning C anymore.\n",
        "%matplotlib inline \n",
        "SVC_20_cplot = Pipeline([\n",
        "                         ('vect', CountVectorizer()),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('clf', LinearSVC(penalty='l2',loss='squared_hinge',dual=True))\n",
        "])\n",
        "params = {'clf__C': (0.2, 0.4, 0.6, 0.8, 0.85, 0.9, 0.95, 1.05, 1.1, 1.2, 1.5, 2, 3, 5, 7)}\n",
        "SVC_20_cplot_gs = GridSearchCV(SVC_20_cplot, params, n_jobs=-1)\n",
        "SVC_20_cplot_gs.fit(twentyTrain.data, twentyTrain.target) \n",
        "cs = []\n",
        "cvAccs = []\n",
        "for p, r in zip(SVC_20_cplot_gs.cv_results_['params'], SVC_20_cplot_gs.cv_results_['mean_test_score']):\n",
        "    print(p,r)\n",
        "    cs.append(p['clf__C'])\n",
        "    cvAccs.append(r)\n",
        "fig = plt.figure()\n",
        "plt.plot(cs, cvAccs, 'b.')\n",
        "plt.xlabel('Inverse Regularization Parameter')\n",
        "plt.ylabel('Cross validated accuracy')\n",
        "plt.savefig('imdbCTunePlot', dpi=400)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'clf__C': 0.2} 0.7589717021566716\n",
            "{'clf__C': 0.4} 0.7632142102238252\n",
            "{'clf__C': 0.6} 0.7647169922635814\n",
            "{'clf__C': 0.8} 0.7623304276343422\n",
            "{'clf__C': 0.85} 0.7621537101872939\n",
            "{'clf__C': 0.9} 0.7618886144812974\n",
            "{'clf__C': 0.95} 0.7616235578461492\n",
            "{'clf__C': 1.05} 0.7611815493388626\n",
            "{'clf__C': 1.1} 0.7615350623746557\n",
            "{'clf__C': 1.2} 0.7607396189732728\n",
            "{'clf__C': 1.5} 0.7589719365817618\n",
            "{'clf__C': 2} 0.7582648714393271\n",
            "{'clf__C': 3} 0.7568505458002159\n",
            "{'clf__C': 5} 0.7528730943682108\n",
            "{'clf__C': 7} 0.7508403162707031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nR0REtCWJIyIi2pLEERERbfn/4u++mE4JAT8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nCdgzuw3y1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tuning Count Vec and tfidf, 20 newsgroups\n",
        "SVC_20_feat_tune = Pipeline([\n",
        "                        ('vect', CountVectorizer()),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('clf', LinearSVC(penalty='l2', dual=True, loss='squared_hinge'))                            \n",
        "])\n",
        "params = {'vect__ngram_range': ((1,1), (1,2)),\n",
        "         'vect__max_df': (0.2, 0.4, 0.6, 0.8, 1.0),\n",
        "          'tfidf__sublinear_tf': (True, False),\n",
        "         'clf__C': (0.01, 0.1, 1.0, 10, 20)}\n",
        "\n",
        "SVC_20_feat_tune_gs = GridSearchCV(SVC_20_feat_tune, params, return_train_score=True)\n",
        "SVC_20_feat_tune_gs.fit(twentyTrain.data, twentyTrain.target) \n",
        "\n",
        "for param_name in sorted(params.keys()):\n",
        "  print(\"%s : %r\" % (param_name, SVC_20_feat_tune_gs.best_params_[param_name]))\n",
        "print('Train time for best params:', SVC_20_feat_tune_gs.cv_results_['mean_fit_time'][SVC_20_feat_tune_gs.best_index_])\n",
        "print('Train acc for best params:', SVC_20_feat_tune_gs.cv_results_['mean_train_score'][SVC_20_feat_tune_gs.best_index_])\n",
        "print('CV acc for best params:', SVC_20_feat_tune_gs.best_score_)\n",
        "\n",
        "# Check how the best performs:\n",
        "SVC_20_feat_tune_best = Pipeline([\n",
        "                         ('vect', CountVectorizer(ngram_range=SVC_20_feat_tune_gs.best_params_['vect__ngram_range'],\n",
        "                                                  max_df=SVC_20_feat_tune_gs.best_params_['vect__max_df'])),\n",
        "                         ('tfidf', TfidfTransformer(sublinear_tf=SVC_20_feat_tune_gs.best_params_['tfidf__sublinear_tf'])),\n",
        "                         ('clf', LinearSVC(penalty='l2',\n",
        "                                           loss='squared_hinge',\n",
        "                                           dual=True,\n",
        "                                           C=SVC_20_feat_tune_gs.best_params_['clf__C']))\n",
        "])\n",
        "\n",
        "start = time.time()\n",
        "SVC_20_feat_tune_best.fit(twentyTrain.data, twentyTrain.target)\n",
        "print('Train time:', time.time()-start)\n",
        "# Train acc\n",
        "trainPreds = SVC_20_feat_tune_best.predict(twentyTrain.data)\n",
        "print('Train acc:', accuracy_score(trainPreds, twentyTrain.target))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhCOyGb6u_Is",
        "colab_type": "code",
        "outputId": "f206744d-12f8-4207-b6a2-71b504799307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Best SVC on 20 newsgroups with feature tuning\n",
        "SVC_20_best = Pipeline([\n",
        "                        ('vect', CountVectorizer(ngram_range=(1,2), max_df=0.2)),\n",
        "                        ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
        "                        ('clf', LinearSVC(penalty='l2', C=20.0, dual=True, loss='squared_hinge'))\n",
        "])\n",
        "SVC_20_best.fit(twentyTrain.data, twentyTrain.target)\n",
        "SVC20BestPreds = SVC_20_best.predict(twentyTest.data)\n",
        "print(\"SVC 20 Newsgroups best classifier accuracy: \", accuracy_score(twentyTest.target, SVC20BestPreds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC 20 Newsgroups best classifier accuracy:  0.7048592671269251\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ay8yb4a0owK",
        "colab_type": "code",
        "outputId": "d63d8cbd-b14e-46e6-88da-579f63c30794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Performing first two steps of pipeline separately to be able to study them.\n",
        "# First, look at new feature design\n",
        "CountVec = CountVectorizer(max_df=0.2, ngram_range=(1,2))\n",
        "twentyTrain_count = CountVec.fit_transform(imdbTrain.data)\n",
        "tfidfVec = TfidfTransformer(sublinear_tf=True).fit(twentyTrain_count)\n",
        "twentyTrain_tfidf = tfidfVec.transform(twentyTrain_count)\n",
        "print('New design shape:', twentyTrain_tfidf.shape)\n",
        "# Now, look at default\n",
        "CountVec_def = CountVectorizer()\n",
        "twentyTrain_count_def = CountVec_def.fit_transform(twentyTrain.data)\n",
        "tfidfVec_def = TfidfTransformer().fit(twentyTrain_count_def)\n",
        "twentyTrain_tfidf_def = tfidfVec_def.transform(twentyTrain_count_def)\n",
        "print('Default shape:', twentyTrain_tfidf_def.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New design shape: (25000, 1513704)\n",
            "Default shape: (11314, 101631)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
